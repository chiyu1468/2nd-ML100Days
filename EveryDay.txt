

===========================Daliy Topic Index:===============================

1. 資料取得 -> 格式問題 (csv, binary, xml ...) -> 主要介紹工具 Pandas
    1-1. locate 功能 : read/write [02,03]
    1-2. 基本分析功能 : max/min [02,03], descript [05]
    1-3. 進階資料調整 : merge/groupby/subset/transfer [08], cut [12], drop/concat [17]
    1-4. 檔案存取功能 : read_csv [02], to_csv [16]
    1-5. 功能複合語法 :
        - dtype_df.groupby("Column Type").aggregate('count').reset_index() [18]

2. 資料處理
    2-1. Label Process: 
        2-1-1. one-hot Encoding [04]
        2-1-2. Label Encoding [04]
    2-2. Feature Process:
        2-2-1. missing/outliers feature [06,07,19,20]
        2-2-2. basic :
            a. Graph: Histogram [05,14], 
                      Empirical Cumulative Density [06],
                      scatter plot [09],
                      barplot(sns) [11],
                      Heatmap [15],
            b. distribution analysis:
                - mean median quantile max min [07],
                - Pearson correlation coefficient [09],
                - Mixture Models / Kernel Density Estimation [11],
            c. data type category - object/continue number/discrete number [18]
        2-2-3. Transfer:
            a. Object Data Encoding: Label/Mean/Hash [23,24] 
               注意:雖然用一樣的工具 但是與處理 label 時候對象不同
            b. discrete number Data transform [25]
            c. continue number Data transform : 
                - Base on Domail Knowledge [26],
                - Base on statistics (ex. 群聚編碼) [27],
            d. Scalering:
                - MinMax
                - normalization (value 0~1)
                - standardization (mean 1, std 0)
            e. Reduction:
                - correlation threshold [28]
                - LASSO [28]
    2-3. Dataset Split:
        2-3-1. from sklearn.model_selection import train_test_split [34]

3. 預測模型
    3-1. Models:
        3-1-1. Classification
        3-1-2. Regression:
            a. Linear Regression(y=ax+b)
            b. Logistic Regression(sigmoid)
    3-2. Loss Function:
        3-2-1. F-score [36]
        3-2-2. Ln-Norm(LSE for n=2 / LAD for n=1)
        3-2-3. cross entropy
    3-3. Regularization:
        3-3-1. Linear Regression
            - LASSO / Ridge [39]

4. Training and Validation:
    - Overfit / Underfit
    - Cross Validation [?]

P1. 工具類
    P1-1. matplotlib
        - subplot [14]
    P1-2. seaborn [11]
        - PairGrid(進階 Heatmap) [15]

============================================================================











import warnings
warnings.filterwarnings('ignore')

===================================
Day 6 
------
Empirical Cumulative Density Plot

matplotlib pyplot 的label與顯示區間
plt.plot(x,y)
plt.xlabel('Value')
plt.ylabel('ECDF')
plt.xlim([x.min(), x.max() * 1.05]) # 限制顯示圖片的範圍
plt.ylim([-0.05,1.05]) # 限制顯示圖片的範圍

===================================
Day 7 百分位數
------
Pandas 內建方法比較快
q_all = [app_train['AMT_ANNUITY'].quantile(i) for i in np.arange(0,1.01,0.01)]


===================================
Day 11 頗完整的例子
------
plt.style.use('ggplot')
pd.cut
pd.groupby
sns.barplot

===================================
Day 12 13 
------
沒用的 BJ4

===================================
Day 14
------
subplot 排版

===================================
Day 15 畫圖
------
Heatmap
seborn.PairGrid

===================================
Day 16 頗完整的例子
------
LabelEncoder OneHotEncoder 
填補器:設定缺失值補
縮放器:設定特徵縮放
LogisticRegression

===================================
Day 17
------
estimator = LogisticRegression()
estimator.fit(train_X, train_Y)
pred = estimator.predict(test_X)


===================================
Day 18
------
Pandas DataFrame 分別取出 int64, float64, object 三種類型


===================================
Day 19
------
# 檢查欄位缺值數量 (去掉.head()可以顯示全部)
df.isnull().sum().sort_values(ascending=False).head()
概念:
https://morvanzhou.github.io/tutorials/machine-learning/sklearn/3-2-cross-validation1/

# 填充缺值
df = df.fillna(-1)
df_mn = df.fillna(df.mean())

# 移除缺值 pandas.DataFrame.dropna
df = df.dropna()

===================================
Day 20 21 探討資料偏移與處理離群資料點
------
df['1stFlrSF'].clip(lower_bound, upper_bound)

keep_indexs = (df['1stFlrSF']> lower_bound) & (df['1stFlrSF']< upper_bound)
df_drop = df[keep_indexs]

np.log1p

boxcox

===================================
Day 22
------
這個作業有點硬套，我不懂 one hot encode 為何可以用 LinearRegression 來處理

===================================
Day 23
------
mean Encoding 語法可以用
mean_df = data.groupby([c])['Survived'].mean().reset_index()
mean_df.columns = [c, f'{c}_mean']

===================================
Day 24
------
df.select_dtypes(include=["object"]).apply(pd.Series.nunique)
count_df = df.groupby(['Ticket'])['Name'].agg({'Ticket_Count':'size'}).reset_index()

===================================
Day 26 27 綜合編碼
------


===================================
Day 29 30
------
跟規定的方式認真 你就輸了

===================================
Day 34
------
DataSet切割工具
from sklearn.model_selection import train_test_split

===================================
Day 36
------
r2_score
https://en.wikipedia.org/wiki/Coefficient_of_determination




