
import warnings
warnings.filterwarnings('ignore')

===================================
Day 6 
------
Empirical Cumulative Density Plot

matplotlib pyplot 的label與顯示區間
plt.plot(x,y)
plt.xlabel('Value')
plt.ylabel('ECDF')
plt.xlim([x.min(), x.max() * 1.05]) # 限制顯示圖片的範圍
plt.ylim([-0.05,1.05]) # 限制顯示圖片的範圍

===================================
Day 7 百分位數
------
Pandas 內建方法比較快
q_all = [app_train['AMT_ANNUITY'].quantile(i) for i in np.arange(0,1.01,0.01)]


===================================
Day 11 頗完整的例子
------
plt.style.use('ggplot')
pd.cut
pd.groupby
sns.barplot

===================================
Day 12 13 
------
沒用的 BJ4

===================================
Day 14
------
subplot 排版

===================================
Day 15 畫圖
------
Heatmap
seborn.PairGrid

===================================
Day 16 頗完整的例子
------
LabelEncoder OneHotEncoder 
填補器:設定缺失值補
縮放器:設定特徵縮放
LogisticRegression

===================================
Day 17
------
estimator = LogisticRegression()
estimator.fit(train_X, train_Y)
pred = estimator.predict(test_X)


===================================
Day 18
------
Pandas DataFrame 分別取出 int64, float64, object 三種類型


===================================
Day 19
------
# 檢查欄位缺值數量 (去掉.head()可以顯示全部)
df.isnull().sum().sort_values(ascending=False).head()
概念:
https://morvanzhou.github.io/tutorials/machine-learning/sklearn/3-2-cross-validation1/

# 填充缺值
df = df.fillna(-1)
df_mn = df.fillna(df.mean())

# 移除缺值 pandas.DataFrame.dropna
df = df.dropna()

===================================
Day 20 21 探討資料偏移與處理離群資料點
------
df['1stFlrSF'].clip(lower_bound, upper_bound)

keep_indexs = (df['1stFlrSF']> lower_bound) & (df['1stFlrSF']< upper_bound)
df_drop = df[keep_indexs]

np.log1p

boxcox

===================================
Day 22
------
這個作業有點硬套，我不懂 one hot encode 為何可以用 LinearRegression 來處理

===================================
Day 23
------
mean Encoding 語法可以用
mean_df = data.groupby([c])['Survived'].mean().reset_index()
mean_df.columns = [c, f'{c}_mean']

===================================
Day 24
------
df.select_dtypes(include=["object"]).apply(pd.Series.nunique)
count_df = df.groupby(['Ticket'])['Name'].agg({'Ticket_Count':'size'}).reset_index()

===================================
Day 26 27 綜合編碼
------


===================================
Day 29 30
------
跟規定的方式認真 你就輸了



===================================
Day 36
------
r2_score
https://en.wikipedia.org/wiki/Coefficient_of_determination




